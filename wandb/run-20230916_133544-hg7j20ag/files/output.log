
(59352, 100)
Traceback (most recent call last):
  File "/home2/swethavipparla/anlp/Assignments/A2/mywandb.py", line 179, in random_search
    train_loss, val_loss = train(cfg.optimizer, cfg.embedding_dimension, cfg.hidden_dimension, cfg.dropout_rate, cfg.learning_rate)
  File "/home2/swethavipparla/anlp/Assignments/A2/mywandb.py", line 120, in train
    model = mdl.ELMO(embedding_matrix(word_to_ix, glove_vectors), len(word_to_ix), hidden_dimension, dropout_rate)
  File "/home2/swethavipparla/anlp/Assignments/A2/elmo_model.py", line 10, in __init__
    self.lstm = nn.LSTM(embedding_matrix.shape[1], hidden_dim, num_layers, dropout=dropout, batch_first=True, bidirectional=True)
  File "/home2/swethavipparla/miniconda3/envs/anlp/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 711, in __init__
    super().__init__('LSTM', *args, **kwargs)
  File "/home2/swethavipparla/miniconda3/envs/anlp/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 98, in __init__
    w_ih = Parameter(torch.empty((gate_size, layer_input_size), **factory_kwargs))
RuntimeError: [enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 112725116928 bytes. Error code 12 (Cannot allocate memory)