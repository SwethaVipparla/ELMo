{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4usVcxsDbeb",
        "outputId": "70d83b4c-9b5c-471c-c290-169c1a116a68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check if cuda is available\n",
        "import torch\n",
        "torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVe1pr3KFKvQ",
        "outputId": "949445a6-edf1-437a-f99a-255c801d5f52"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import elmo_dataset as ds\n",
        "import nltk\n",
        "import unicodedata\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/swetha/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/swetha/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "def preprocess(csv):\n",
        "    df = pd.read_csv(csv)\n",
        "\n",
        "    df = df.dropna()\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    def normalize_unicode(s):\n",
        "        return unicodedata.normalize('NFD', s)\n",
        "\n",
        "    def preprocess_text(text):\n",
        "        text = normalize_unicode(text)\n",
        "        text = re.sub(r\"(.)(\\1{2,})\", r\"\\1\", text)\n",
        "        text = re.sub(r\"[^a-zA-Z.,!?]+\", \" \", text)\n",
        "        text = text.strip().lower()\n",
        "        return text\n",
        "\n",
        "    nltk.download('punkt')\n",
        "\n",
        "    df['Description'] = df['Description'].apply(preprocess_text)\n",
        "    df['Description'] = df['Description'].apply(nltk.word_tokenize)\n",
        "    \n",
        "    return df\n",
        "\n",
        "train_df = preprocess('train.csv')\n",
        "test_df = preprocess('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rONzBJnkDaZt"
      },
      "outputs": [],
      "source": [
        "PRE_TRAIN_SET = 8000\n",
        "PRE_VAL_SET = 2000\n",
        "DOWNSTREAM_TRAIN_SET = 80000\n",
        "DOWNSTREAM_VAL_SET = 20000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CeE4PxpCFKvU"
      },
      "outputs": [],
      "source": [
        "train_set = list(train_df['Description'])\n",
        "pre_train_set = train_set[:PRE_TRAIN_SET]\n",
        "pre_val_set = train_set[PRE_TRAIN_SET:PRE_TRAIN_SET+PRE_VAL_SET]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbuIOGvQFKvU",
        "outputId": "186d6c34-6f84-44d9-f246-59aa8d982cc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "59352\n"
          ]
        }
      ],
      "source": [
        "vocab = ds.ELMO_Dataset.create_vocab(train_set)\n",
        "word_to_ix = {word: idx for idx, word in enumerate(vocab)}\n",
        "print(len(word_to_ix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LElWE0J5FKvV"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    padded_batch = pad_sequence(batch, batch_first=True, padding_value=word_to_ix['<pad>'])\n",
        "    lengths = torch.LongTensor([len(x) for x in batch])\n",
        "\n",
        "    input_tensor = torch.LongTensor(padded_batch[:, :-1])\n",
        "    target_truth = torch.LongTensor(padded_batch[:, 1:])\n",
        "\n",
        "    return input_tensor, target_truth, lengths - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Sh0lM0plFKvV"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "forward_pre_train_dataset = ds.ELMO_Dataset(pre_train_set, word_to_ix, 'Forward')\n",
        "forward_pre_val_dataset = ds.ELMO_Dataset(pre_val_set, word_to_ix, 'Forward')\n",
        "\n",
        "backward_pre_train_dataset = ds.ELMO_Dataset(pre_train_set, word_to_ix, 'Backward')\n",
        "backward_pre_val_dataset = ds.ELMO_Dataset(pre_val_set, word_to_ix, 'Backward')\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "forward_pre_train_loader = DataLoader(forward_pre_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=2)\n",
        "forward_pre_val_loader = DataLoader(forward_pre_val_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=2)\n",
        "\n",
        "backward_pre_train_loader = DataLoader(backward_pre_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=2)\n",
        "backward_pre_val_loader = DataLoader(backward_pre_val_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xudp-rpZFKvV",
        "outputId": "a3134790-9931-4191-ff59-d79bcea9fa6b"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import gensim.downloader\n",
        "\n",
        "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "T2rWFfleFKvW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def embedding_matrix(word_to_ix, glove_vectors):\n",
        "    embedding_dim = glove_vectors.vector_size\n",
        "    embedding_matrix = np.zeros((len(word_to_ix), embedding_dim))\n",
        "\n",
        "    average_vector = np.mean(glove_vectors.vectors, axis=0)\n",
        "\n",
        "    special_token_embeddings = {\n",
        "        '<pad>': np.zeros(embedding_dim),\n",
        "        '<unk>': average_vector,\n",
        "        '<sos>': np.random.randn(embedding_dim),\n",
        "        '<eos>': np.random.randn(embedding_dim)\n",
        "    }\n",
        "\n",
        "    for word, i in word_to_ix.items():\n",
        "        if word in glove_vectors:\n",
        "            embedding_vector = glove_vectors[word]\n",
        "        else:\n",
        "            embedding_vector = special_token_embeddings.get(word, average_vector)\n",
        "\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    print(embedding_matrix.shape)\n",
        "\n",
        "    return torch.FloatTensor(embedding_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mcwF22ehkQ0A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class ELMO(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_dim, num_layers, dropout, filename=None):\n",
        "        super(ELMO, self).__init__()\n",
        "\n",
        "        self.embedding_matrix = embedding_matrix\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix)\n",
        "        self.forward_lstm = nn.LSTM(embedding_matrix.shape[1], hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
        "        self.backward_lstm = nn.LSTM(embedding_matrix.shape[1], hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
        "        self.forward_linear = nn.Linear(hidden_dim, embedding_matrix.shape[0])\n",
        "        self.backward_linear = nn.Linear(hidden_dim, embedding_matrix.shape[0])\n",
        "\n",
        "        if filename:\n",
        "            self.load_state_dict(torch.load(filename), strict=False)\n",
        "\n",
        "    def forward(self, input_tensor, lengths, forward):\n",
        "        embedded = self.embedding(input_tensor)\n",
        "        output = pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n",
        "        if forward:\n",
        "            output, (h_n, c_n) = self.forward_lstm(output, None)\n",
        "            output, _ = pad_packed_sequence(output, batch_first=True)\n",
        "            output = self.forward_linear(output)\n",
        "        else:\n",
        "            output, (h_n, c_n) = self.backward_lstm(output, None)\n",
        "            output, _ = pad_packed_sequence(output, batch_first=True)\n",
        "            output = self.backward_linear(output)\n",
        "\n",
        "        return output, h_n, c_n, embedded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sFvUaUuaFKvX"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def run_epoch(model, data_loader, loss_fn, epoch, forward, optimizer=None):\n",
        "    if optimizer:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    p_bar = tqdm(data_loader)\n",
        "\n",
        "    for (input_tensor, target_truth, lengths) in p_bar:\n",
        "\n",
        "        input_tensor = input_tensor.cuda()\n",
        "        target_truth = target_truth.cuda()\n",
        "\n",
        "        output, _, _, _= model(input_tensor, lengths, forward)\n",
        "        output = output.reshape(-1, output.shape[2])\n",
        "\n",
        "        target_truth = target_truth.reshape(-1)\n",
        "        loss = loss_fn(output, target_truth)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if optimizer:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        mean_loss = total_loss / len(data_loader)\n",
        "\n",
        "        p_bar.set_description(f'{\"T\" if optimizer else \"V\"} Loss: {mean_loss:.4f}, count: {epoch}')\n",
        "\n",
        "    return mean_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "B_bi722aFKvX"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def train(optimizer, embedding_dimension, hidden_dimension, dropout_rate, learning_rate):\n",
        "    num_epochs = 50\n",
        "\n",
        "    glove_vectors = gensim.downloader.load(f'glove-wiki-gigaword-{embedding_dimension}')\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=word_to_ix['<pad>'])\n",
        "\n",
        "    model = ELMO(embedding_matrix(word_to_ix, glove_vectors), hidden_dimension, 1, dropout_rate)\n",
        "\n",
        "    optimizer = getattr(torch.optim, optimizer)(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.cuda()\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    all_val_loss = []\n",
        "    all_train_loss = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        forward_train_loss = run_epoch(model, forward_pre_train_loader, loss_fn, epoch+1, 1, optimizer)\n",
        "        backward_train_loss = run_epoch(model, backward_pre_train_loader, loss_fn, epoch+1, 0, optimizer)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            forward_val_loss = run_epoch(model, forward_pre_val_loader, loss_fn, epoch+1, 1)\n",
        "            backward_val_loss = run_epoch(model, backward_pre_val_loader, loss_fn, epoch+1, 0)\n",
        "\n",
        "        print('Epoch: {}, F Train Loss: {:.4f}, F Val Loss: {:.4f}'.format(epoch+1, forward_train_loss, forward_val_loss))\n",
        "        print('Epoch: {}, B Train Loss: {:.4f}, B Val Loss: {:.4f}'.format(epoch+1, backward_train_loss, backward_val_loss))\n",
        "        average_train_loss = (forward_train_loss + backward_train_loss) / 2\n",
        "        average_val_loss = (forward_val_loss + backward_val_loss) / 2\n",
        "\n",
        "        all_train_loss.append(average_train_loss)\n",
        "        all_val_loss.append(average_val_loss)\n",
        "        print('Average Train Loss: {:.4f}, Average Val Loss: {:.4f}'.format(average_train_loss, average_val_loss))\n",
        "        print('-------------------------------------------------------')\n",
        "\n",
        "        if average_val_loss < best_val_loss:\n",
        "            counter = 0\n",
        "            best_val_loss = average_val_loss\n",
        "            torch.save(model.state_dict(), 'best_elmo_model.pth')\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter == 3:\n",
        "                break\n",
        "\n",
        "    return all_train_loss, all_val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc3pjymYcyXw",
        "outputId": "84c73cd0-79b0-4de6-8dbe-79165cbc475f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(59352, 100)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/swetha/.conda/envs/ml/lib/python3.11/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "T Loss: 7.5116, count: 1: 100%|██████████| 250/250 [00:15<00:00, 15.80it/s]\n",
            "T Loss: 7.5147, count: 1: 100%|██████████| 250/250 [00:16<00:00, 15.58it/s]\n",
            "V Loss: 7.1333, count: 1: 100%|██████████| 63/63 [00:01<00:00, 37.36it/s]\n",
            "V Loss: 7.1156, count: 1: 100%|██████████| 63/63 [00:01<00:00, 38.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, F Train Loss: 7.5116, F Val Loss: 7.1333\n",
            "Epoch: 1, B Train Loss: 7.5147, B Val Loss: 7.1156\n",
            "Average Train Loss: 7.5132, Average Val Loss: 7.1245\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 6.8360, count: 2: 100%|██████████| 250/250 [00:16<00:00, 15.35it/s]\n",
            "T Loss: 6.8181, count: 2: 100%|██████████| 250/250 [00:16<00:00, 15.08it/s]\n",
            "V Loss: 6.9684, count: 2: 100%|██████████| 63/63 [00:01<00:00, 35.82it/s]\n",
            "V Loss: 6.9417, count: 2: 100%|██████████| 63/63 [00:01<00:00, 36.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2, F Train Loss: 6.8360, F Val Loss: 6.9684\n",
            "Epoch: 2, B Train Loss: 6.8181, B Val Loss: 6.9417\n",
            "Average Train Loss: 6.8271, Average Val Loss: 6.9550\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 6.5901, count: 3: 100%|██████████| 250/250 [00:17<00:00, 14.66it/s]\n",
            "T Loss: 6.5738, count: 3: 100%|██████████| 250/250 [00:17<00:00, 14.43it/s]\n",
            "V Loss: 6.7572, count: 3: 100%|██████████| 63/63 [00:01<00:00, 34.95it/s]\n",
            "V Loss: 6.7535, count: 3: 100%|██████████| 63/63 [00:01<00:00, 36.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3, F Train Loss: 6.5901, F Val Loss: 6.7572\n",
            "Epoch: 3, B Train Loss: 6.5738, B Val Loss: 6.7535\n",
            "Average Train Loss: 6.5819, Average Val Loss: 6.7554\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 6.3381, count: 4: 100%|██████████| 250/250 [00:17<00:00, 14.62it/s]\n",
            "T Loss: 6.3320, count: 4: 100%|██████████| 250/250 [00:17<00:00, 14.54it/s]\n",
            "V Loss: 6.5770, count: 4: 100%|██████████| 63/63 [00:01<00:00, 36.02it/s]\n",
            "V Loss: 6.5741, count: 4: 100%|██████████| 63/63 [00:01<00:00, 35.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4, F Train Loss: 6.3381, F Val Loss: 6.5770\n",
            "Epoch: 4, B Train Loss: 6.3320, B Val Loss: 6.5741\n",
            "Average Train Loss: 6.3350, Average Val Loss: 6.5755\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 6.1149, count: 5: 100%|██████████| 250/250 [00:17<00:00, 14.67it/s]\n",
            "T Loss: 6.1165, count: 5: 100%|██████████| 250/250 [00:17<00:00, 14.51it/s]\n",
            "V Loss: 6.4242, count: 5: 100%|██████████| 63/63 [00:01<00:00, 35.13it/s]\n",
            "V Loss: 6.4398, count: 5: 100%|██████████| 63/63 [00:01<00:00, 35.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5, F Train Loss: 6.1149, F Val Loss: 6.4242\n",
            "Epoch: 5, B Train Loss: 6.1165, B Val Loss: 6.4398\n",
            "Average Train Loss: 6.1157, Average Val Loss: 6.4320\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 5.9191, count: 6: 100%|██████████| 250/250 [00:16<00:00, 14.78it/s]\n",
            "T Loss: 5.9415, count: 6: 100%|██████████| 250/250 [00:16<00:00, 14.80it/s]\n",
            "V Loss: 6.3171, count: 6: 100%|██████████| 63/63 [00:01<00:00, 35.18it/s]\n",
            "V Loss: 6.3362, count: 6: 100%|██████████| 63/63 [00:01<00:00, 35.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 6, F Train Loss: 5.9191, F Val Loss: 6.3171\n",
            "Epoch: 6, B Train Loss: 5.9415, B Val Loss: 6.3362\n",
            "Average Train Loss: 5.9303, Average Val Loss: 6.3267\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 5.7535, count: 7: 100%|██████████| 250/250 [00:16<00:00, 14.71it/s]\n",
            "T Loss: 5.7938, count: 7: 100%|██████████| 250/250 [00:16<00:00, 14.78it/s]\n",
            "V Loss: 6.2266, count: 7: 100%|██████████| 63/63 [00:01<00:00, 36.12it/s]\n",
            "V Loss: 6.2663, count: 7: 100%|██████████| 63/63 [00:01<00:00, 36.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 7, F Train Loss: 5.7535, F Val Loss: 6.2266\n",
            "Epoch: 7, B Train Loss: 5.7938, B Val Loss: 6.2663\n",
            "Average Train Loss: 5.7736, Average Val Loss: 6.2464\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 5.6123, count: 8: 100%|██████████| 250/250 [00:16<00:00, 14.88it/s]\n",
            "T Loss: 5.6646, count: 8: 100%|██████████| 250/250 [00:16<00:00, 14.81it/s]\n",
            "V Loss: 6.1541, count: 8: 100%|██████████| 63/63 [00:01<00:00, 36.63it/s]\n",
            "V Loss: 6.2040, count: 8: 100%|██████████| 63/63 [00:01<00:00, 36.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 8, F Train Loss: 5.6123, F Val Loss: 6.1541\n",
            "Epoch: 8, B Train Loss: 5.6646, B Val Loss: 6.2040\n",
            "Average Train Loss: 5.6385, Average Val Loss: 6.1791\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 5.4871, count: 9: 100%|██████████| 250/250 [00:16<00:00, 15.05it/s]\n",
            "T Loss: 5.5469, count: 9: 100%|██████████| 250/250 [00:16<00:00, 15.16it/s]\n",
            "V Loss: 6.1093, count: 9: 100%|██████████| 63/63 [00:01<00:00, 36.36it/s]\n",
            "V Loss: 6.1469, count: 9: 100%|██████████| 63/63 [00:01<00:00, 35.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 9, F Train Loss: 5.4871, F Val Loss: 6.1093\n",
            "Epoch: 9, B Train Loss: 5.5469, B Val Loss: 6.1469\n",
            "Average Train Loss: 5.5170, Average Val Loss: 6.1281\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 5.3729, count: 10: 100%|██████████| 250/250 [00:22<00:00, 11.36it/s]\n",
            "T Loss: 5.4361, count: 10: 100%|██████████| 250/250 [00:16<00:00, 14.77it/s]\n",
            "V Loss: 6.0589, count: 10: 100%|██████████| 63/63 [00:01<00:00, 36.14it/s]\n",
            "V Loss: 6.1045, count: 10: 100%|██████████| 63/63 [00:01<00:00, 35.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10, F Train Loss: 5.3729, F Val Loss: 6.0589\n",
            "Epoch: 10, B Train Loss: 5.4361, B Val Loss: 6.1045\n",
            "Average Train Loss: 5.4045, Average Val Loss: 6.0817\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 5.2685, count: 11: 100%|██████████| 250/250 [00:17<00:00, 14.62it/s]\n",
            "T Loss: 5.3338, count: 11: 100%|██████████| 250/250 [00:17<00:00, 14.67it/s]\n",
            "V Loss: 6.0257, count: 11: 100%|██████████| 63/63 [00:01<00:00, 35.91it/s]\n",
            "V Loss: 6.0683, count: 11: 100%|██████████| 63/63 [00:01<00:00, 35.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 11, F Train Loss: 5.2685, F Val Loss: 6.0257\n",
            "Epoch: 11, B Train Loss: 5.3338, B Val Loss: 6.0683\n",
            "Average Train Loss: 5.3011, Average Val Loss: 6.0470\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 5.1729, count: 12: 100%|██████████| 250/250 [00:16<00:00, 14.79it/s]\n",
            "T Loss: 5.2396, count: 12: 100%|██████████| 250/250 [00:17<00:00, 14.44it/s]\n",
            "V Loss: 5.9961, count: 12: 100%|██████████| 63/63 [00:01<00:00, 35.00it/s]\n",
            "V Loss: 6.0423, count: 12: 100%|██████████| 63/63 [00:01<00:00, 35.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 12, F Train Loss: 5.1729, F Val Loss: 5.9961\n",
            "Epoch: 12, B Train Loss: 5.2396, B Val Loss: 6.0423\n",
            "Average Train Loss: 5.2062, Average Val Loss: 6.0192\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 5.0832, count: 13: 100%|██████████| 250/250 [00:17<00:00, 14.41it/s]\n",
            "T Loss: 5.1509, count: 13: 100%|██████████| 250/250 [00:17<00:00, 14.29it/s]\n",
            "V Loss: 5.9714, count: 13: 100%|██████████| 63/63 [00:01<00:00, 35.39it/s]\n",
            "V Loss: 6.0130, count: 13: 100%|██████████| 63/63 [00:01<00:00, 34.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 13, F Train Loss: 5.0832, F Val Loss: 5.9714\n",
            "Epoch: 13, B Train Loss: 5.1509, B Val Loss: 6.0130\n",
            "Average Train Loss: 5.1170, Average Val Loss: 5.9922\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 5.0025, count: 14: 100%|██████████| 250/250 [00:17<00:00, 14.42it/s]\n",
            "T Loss: 5.0681, count: 14: 100%|██████████| 250/250 [00:17<00:00, 14.47it/s]\n",
            "V Loss: 5.9432, count: 14: 100%|██████████| 63/63 [00:01<00:00, 35.03it/s]\n",
            "V Loss: 5.9874, count: 14: 100%|██████████| 63/63 [00:01<00:00, 34.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 14, F Train Loss: 5.0025, F Val Loss: 5.9432\n",
            "Epoch: 14, B Train Loss: 5.0681, B Val Loss: 5.9874\n",
            "Average Train Loss: 5.0353, Average Val Loss: 5.9653\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 4.9260, count: 15: 100%|██████████| 250/250 [00:17<00:00, 14.26it/s]\n",
            "T Loss: 4.9911, count: 15: 100%|██████████| 250/250 [00:17<00:00, 14.17it/s]\n",
            "V Loss: 5.9354, count: 15: 100%|██████████| 63/63 [00:01<00:00, 34.71it/s]\n",
            "V Loss: 5.9751, count: 15: 100%|██████████| 63/63 [00:01<00:00, 35.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 15, F Train Loss: 4.9260, F Val Loss: 5.9354\n",
            "Epoch: 15, B Train Loss: 4.9911, B Val Loss: 5.9751\n",
            "Average Train Loss: 4.9585, Average Val Loss: 5.9553\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 4.8529, count: 16: 100%|██████████| 250/250 [00:17<00:00, 14.24it/s]\n",
            "T Loss: 4.9155, count: 16: 100%|██████████| 250/250 [00:17<00:00, 14.27it/s]\n",
            "V Loss: 5.9254, count: 16: 100%|██████████| 63/63 [00:01<00:00, 33.57it/s]\n",
            "V Loss: 5.9625, count: 16: 100%|██████████| 63/63 [00:01<00:00, 34.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 16, F Train Loss: 4.8529, F Val Loss: 5.9254\n",
            "Epoch: 16, B Train Loss: 4.9155, B Val Loss: 5.9625\n",
            "Average Train Loss: 4.8842, Average Val Loss: 5.9440\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 4.7847, count: 17: 100%|██████████| 250/250 [00:17<00:00, 14.17it/s]\n",
            "T Loss: 4.8471, count: 17: 100%|██████████| 250/250 [00:17<00:00, 14.24it/s]\n",
            "V Loss: 5.9221, count: 17: 100%|██████████| 63/63 [00:01<00:00, 34.08it/s]\n",
            "V Loss: 5.9548, count: 17: 100%|██████████| 63/63 [00:01<00:00, 33.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 17, F Train Loss: 4.7847, F Val Loss: 5.9221\n",
            "Epoch: 17, B Train Loss: 4.8471, B Val Loss: 5.9548\n",
            "Average Train Loss: 4.8159, Average Val Loss: 5.9385\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 4.7193, count: 18: 100%|██████████| 250/250 [00:17<00:00, 14.25it/s]\n",
            "T Loss: 4.7816, count: 18: 100%|██████████| 250/250 [00:17<00:00, 14.31it/s]\n",
            "V Loss: 5.9137, count: 18: 100%|██████████| 63/63 [00:01<00:00, 34.64it/s]\n",
            "V Loss: 5.9394, count: 18: 100%|██████████| 63/63 [00:01<00:00, 34.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 18, F Train Loss: 4.7193, F Val Loss: 5.9137\n",
            "Epoch: 18, B Train Loss: 4.7816, B Val Loss: 5.9394\n",
            "Average Train Loss: 4.7504, Average Val Loss: 5.9266\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 4.6592, count: 19: 100%|██████████| 250/250 [00:17<00:00, 14.08it/s]\n",
            "T Loss: 4.7193, count: 19: 100%|██████████| 250/250 [00:17<00:00, 13.98it/s]\n",
            "V Loss: 5.9092, count: 19: 100%|██████████| 63/63 [00:01<00:00, 34.16it/s]\n",
            "V Loss: 5.9297, count: 19: 100%|██████████| 63/63 [00:01<00:00, 34.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 19, F Train Loss: 4.6592, F Val Loss: 5.9092\n",
            "Epoch: 19, B Train Loss: 4.7193, B Val Loss: 5.9297\n",
            "Average Train Loss: 4.6892, Average Val Loss: 5.9195\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 4.6024, count: 20: 100%|██████████| 250/250 [00:17<00:00, 14.19it/s]\n",
            "T Loss: 4.6613, count: 20: 100%|██████████| 250/250 [00:17<00:00, 14.01it/s]\n",
            "V Loss: 5.9161, count: 20: 100%|██████████| 63/63 [00:01<00:00, 34.40it/s]\n",
            "V Loss: 5.9404, count: 20: 100%|██████████| 63/63 [00:01<00:00, 33.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 20, F Train Loss: 4.6024, F Val Loss: 5.9161\n",
            "Epoch: 20, B Train Loss: 4.6613, B Val Loss: 5.9404\n",
            "Average Train Loss: 4.6319, Average Val Loss: 5.9283\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 4.5464, count: 21: 100%|██████████| 250/250 [00:17<00:00, 13.98it/s]\n",
            "T Loss: 4.6047, count: 21: 100%|██████████| 250/250 [00:17<00:00, 14.04it/s]\n",
            "V Loss: 5.9119, count: 21: 100%|██████████| 63/63 [00:01<00:00, 35.02it/s]\n",
            "V Loss: 5.9353, count: 21: 100%|██████████| 63/63 [00:01<00:00, 34.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 21, F Train Loss: 4.5464, F Val Loss: 5.9119\n",
            "Epoch: 21, B Train Loss: 4.6047, B Val Loss: 5.9353\n",
            "Average Train Loss: 4.5756, Average Val Loss: 5.9236\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 4.4953, count: 22: 100%|██████████| 250/250 [00:17<00:00, 13.94it/s]\n",
            "T Loss: 4.5512, count: 22: 100%|██████████| 250/250 [00:17<00:00, 14.02it/s]\n",
            "V Loss: 5.9191, count: 22: 100%|██████████| 63/63 [00:01<00:00, 34.90it/s]\n",
            "V Loss: 5.9396, count: 22: 100%|██████████| 63/63 [00:01<00:00, 34.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 22, F Train Loss: 4.4953, F Val Loss: 5.9191\n",
            "Epoch: 22, B Train Loss: 4.5512, B Val Loss: 5.9396\n",
            "Average Train Loss: 4.5232, Average Val Loss: 5.9293\n",
            "-------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "all_emlo_train_loss, all_elmo_val_loss = train('Adam', 100, 100, 0.2, 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RatJ0z5XcyXw"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class Downstream_Dataset(Dataset):\n",
        "    def __init__(self, data_set, labels, word_to_ix):\n",
        "        self.data_set = [['<sos>'] + x + ['<eos>'] for x in data_set]\n",
        "        self.word_to_ix = word_to_ix\n",
        "        self.indexed_data = [[word_to_ix.get(word, word_to_ix['<unk>']) for word in sentence] for sentence in self.data_set]\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_set)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.indexed_data[idx]), torch.tensor(self.indexed_data[idx][::-1]), torch.tensor(self.labels[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "p-SU9a_GcyXw"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def downstream_collate_fn(batch):\n",
        "    x_forward = pad_sequence([x[0] for x in batch], batch_first=True, padding_value=word_to_ix['<pad>'])\n",
        "    x_backward = pad_sequence([x[1] for x in batch], batch_first=True, padding_value=word_to_ix['<pad>'])\n",
        "\n",
        "    lengths = torch.LongTensor([len(x[0]) for x in batch])\n",
        "    labels = torch.LongTensor([x[2] - 1 for x in batch])\n",
        "\n",
        "    return x_forward, x_backward, lengths, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7_ivKVg8cyXx"
      },
      "outputs": [],
      "source": [
        "train_labels = list(train_df['Class Index'])\n",
        "\n",
        "downstream_train_set = train_set[PRE_TRAIN_SET+PRE_VAL_SET:PRE_TRAIN_SET+PRE_VAL_SET+DOWNSTREAM_TRAIN_SET]\n",
        "downstream_train_labels = train_labels[PRE_TRAIN_SET+PRE_VAL_SET:PRE_TRAIN_SET+PRE_VAL_SET+DOWNSTREAM_TRAIN_SET]\n",
        "downstream_val_set = train_set[PRE_TRAIN_SET+PRE_VAL_SET+DOWNSTREAM_TRAIN_SET:PRE_TRAIN_SET+PRE_VAL_SET+DOWNSTREAM_TRAIN_SET+DOWNSTREAM_VAL_SET]\n",
        "downstream_val_labels = train_labels[PRE_TRAIN_SET+PRE_VAL_SET+DOWNSTREAM_TRAIN_SET:PRE_TRAIN_SET+PRE_VAL_SET+DOWNSTREAM_TRAIN_SET+DOWNSTREAM_VAL_SET]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Za351g7PcyXx"
      },
      "outputs": [],
      "source": [
        "downstream_train_dataset = Downstream_Dataset(downstream_train_set, downstream_train_labels, word_to_ix)\n",
        "downstream_val_dataset = Downstream_Dataset(downstream_val_set, downstream_val_labels, word_to_ix)\n",
        "\n",
        "downstream_train_loader = DataLoader(downstream_train_dataset, batch_size=32, shuffle=True, pin_memory=True, num_workers=2, collate_fn=downstream_collate_fn)\n",
        "downstream_val_loader = DataLoader(downstream_val_dataset, batch_size=32, shuffle=False, pin_memory=True, num_workers=2, collate_fn=downstream_collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "oByT9VtMcyXx"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Downstream_Model(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_dim, num_layers, dropout):\n",
        "        super(Downstream_Model, self).__init__()\n",
        "\n",
        "        self.embedding_matrix = embedding_matrix\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.elmo = ELMO(embedding_matrix, hidden_dim, num_layers, dropout, 'best_elmo_model.pth')\n",
        "\n",
        "        for param in self.elmo.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.delta = nn.Parameter(torch.randn(1, 3))\n",
        "        self.linear = nn.Linear(hidden_dim * 2, 4)\n",
        "\n",
        "    def forward(self, forward_input, backward_input, lengths):\n",
        "        _, forward_h_n, forward_c_n, input = self.elmo(forward_input, lengths, 1)\n",
        "        _, backward_h_n, backward_c_n, _ = self.elmo(backward_input, lengths, 0)\n",
        "\n",
        "        input = torch.mean(input, dim=1)\n",
        "\n",
        "        forward_h_n = forward_h_n.permute(1, 0, 2)\n",
        "        backward_h_n = backward_h_n.permute(1, 0, 2)\n",
        "        forward_c_n = forward_c_n.permute(1, 0, 2)\n",
        "        backward_c_n = backward_c_n.permute(1, 0, 2)\n",
        "\n",
        "        hidden = torch.cat([forward_h_n, backward_h_n], dim=2)\n",
        "        cell = torch.cat([forward_c_n, backward_c_n], dim=2)\n",
        "\n",
        "        mean = (hidden + cell) / 2\n",
        "        input = torch.cat([input] * mean.shape[1], dim=1).unsqueeze(1)\n",
        "\n",
        "        mean = torch.cat([mean, input], dim=1)\n",
        "        mean = (self.delta / (torch.sum(self.delta))) @ mean\n",
        "        mean = mean.squeeze(0)\n",
        "\n",
        "        output = self.linear(mean)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "F5oTFbr8hNxH"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(output, labels):\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    accuracy = correct / labels.size(0)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-95t09yYcyXx",
        "outputId": "4a22b533-4a99-4895-8cfd-f8f3cad7e7d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(59352, 100)\n"
          ]
        }
      ],
      "source": [
        "num_classes = 4\n",
        "\n",
        "downstream_model = Downstream_Model(embedding_matrix(word_to_ix, glove_vectors), 100, 2, 0.2)\n",
        "downstream_model = downstream_model.cuda()\n",
        "\n",
        "def run_downstream_epoch(model, data_loader, loss_fn, epoch, optimizer=None):\n",
        "    if optimizer:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "\n",
        "    p_bar = tqdm(data_loader)\n",
        "\n",
        "    for (x_forward, x_backward, lengths, labels) in p_bar:\n",
        "        x_forward = x_forward.cuda()\n",
        "        x_backward = x_backward.cuda()\n",
        "\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        output = model(x_forward, x_backward, lengths)\n",
        "\n",
        "        output = output.reshape(-1, output.shape[-1])\n",
        "\n",
        "        loss = loss_fn(output, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if optimizer:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        accuracy = calculate_accuracy(output, labels)\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "        mean_loss = total_loss / len(data_loader)\n",
        "        mean_accuracy = total_accuracy / len(data_loader)\n",
        "\n",
        "        p_bar.set_description(f'{\"T\" if optimizer else \"V\"} Loss: {mean_loss:.4f}, count: {epoch}')\n",
        "\n",
        "    return mean_loss, mean_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ksTr671DcyXx"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def train_downstream_classifier(optimizer):\n",
        "    num_epochs = 100\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=word_to_ix['<pad>'])\n",
        "\n",
        "    optimizer = getattr(torch.optim, optimizer)(downstream_model.parameters(), lr=0.001)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    all_val_loss = []\n",
        "    all_train_loss = []\n",
        "\n",
        "    all_val_accuracy = []\n",
        "    all_train_accuracy = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_accuracy = run_downstream_epoch(downstream_model, downstream_train_loader, loss_fn, epoch+1, optimizer)\n",
        "        all_train_loss.append(train_loss)\n",
        "        all_train_accuracy.append(train_accuracy)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_accuracy = run_downstream_epoch(downstream_model, downstream_val_loader, loss_fn, epoch+1)\n",
        "            all_val_loss.append(val_loss)\n",
        "            all_val_accuracy.append(val_accuracy)\n",
        "\n",
        "        print('Epoch: {}, Train Loss: {:.4f}, Val Loss: {:.4f}, Train Accuracy: {:.4f}, Val Accuracy: {:.4f}'.format(epoch+1, train_loss, val_loss, train_accuracy, val_accuracy))\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            counter = 0\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(downstream_model.state_dict(), 'best_downstream_model_.pth')\n",
        "        else:\n",
        "            counter += 1\n",
        "            if counter == 3:\n",
        "                break\n",
        "\n",
        "    return all_train_loss, all_val_loss, all_train_accuracy, all_val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO75-hRecyXy",
        "outputId": "6af865d9-247d-4bed-c6a2-863ed372ad16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.3933, count: 1: 100%|██████████| 2500/2500 [00:48<00:00, 51.13it/s]\n",
            "V Loss: 0.4135, count: 1: 100%|██████████| 625/625 [00:10<00:00, 58.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train Loss: 0.3933, Val Loss: 0.4135, Train Accuracy: 0.8627, Val Accuracy: 0.8502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.3932, count: 2: 100%|██████████| 2500/2500 [00:49<00:00, 51.02it/s]\n",
            "V Loss: 0.3910, count: 2: 100%|██████████| 625/625 [00:10<00:00, 57.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2, Train Loss: 0.3932, Val Loss: 0.3910, Train Accuracy: 0.8631, Val Accuracy: 0.8544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.3916, count: 3: 100%|██████████| 2500/2500 [00:49<00:00, 50.49it/s]\n",
            "V Loss: 0.4031, count: 3: 100%|██████████| 625/625 [00:10<00:00, 57.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3, Train Loss: 0.3916, Val Loss: 0.4031, Train Accuracy: 0.8633, Val Accuracy: 0.8570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.3893, count: 4: 100%|██████████| 2500/2500 [00:49<00:00, 50.87it/s]\n",
            "V Loss: 0.3886, count: 4: 100%|██████████| 625/625 [00:10<00:00, 58.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4, Train Loss: 0.3893, Val Loss: 0.3886, Train Accuracy: 0.8641, Val Accuracy: 0.8616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.3887, count: 5: 100%|██████████| 2500/2500 [00:49<00:00, 50.95it/s]\n",
            "V Loss: 0.4595, count: 5: 100%|██████████| 625/625 [00:10<00:00, 58.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5, Train Loss: 0.3887, Val Loss: 0.4595, Train Accuracy: 0.8639, Val Accuracy: 0.8262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.3890, count: 6: 100%|██████████| 2500/2500 [00:48<00:00, 51.08it/s]\n",
            "V Loss: 0.3822, count: 6: 100%|██████████| 625/625 [00:10<00:00, 58.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 6, Train Loss: 0.3890, Val Loss: 0.3822, Train Accuracy: 0.8643, Val Accuracy: 0.8626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.3888, count: 7: 100%|██████████| 2500/2500 [00:49<00:00, 50.82it/s]\n",
            "V Loss: 0.4229, count: 7: 100%|██████████| 625/625 [00:10<00:00, 57.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 7, Train Loss: 0.3888, Val Loss: 0.4229, Train Accuracy: 0.8636, Val Accuracy: 0.8422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.3862, count: 8: 100%|██████████| 2500/2500 [00:49<00:00, 50.89it/s]\n",
            "V Loss: 0.4185, count: 8: 100%|██████████| 625/625 [00:10<00:00, 57.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 8, Train Loss: 0.3862, Val Loss: 0.4185, Train Accuracy: 0.8650, Val Accuracy: 0.8475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.3865, count: 9: 100%|██████████| 2500/2500 [00:48<00:00, 51.09it/s]\n",
            "V Loss: 0.3790, count: 9: 100%|██████████| 625/625 [00:10<00:00, 57.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 9, Train Loss: 0.3865, Val Loss: 0.3790, Train Accuracy: 0.8658, Val Accuracy: 0.8632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.3849, count: 10: 100%|██████████| 2500/2500 [00:49<00:00, 50.35it/s]\n",
            "V Loss: 0.3863, count: 10: 100%|██████████| 625/625 [00:10<00:00, 57.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10, Train Loss: 0.3849, Val Loss: 0.3863, Train Accuracy: 0.8654, Val Accuracy: 0.8609\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.3847, count: 11: 100%|██████████| 2500/2500 [00:49<00:00, 50.21it/s]\n",
            "V Loss: 0.4091, count: 11: 100%|██████████| 625/625 [00:10<00:00, 57.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 11, Train Loss: 0.3847, Val Loss: 0.4091, Train Accuracy: 0.8651, Val Accuracy: 0.8524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.3845, count: 12: 100%|██████████| 2500/2500 [00:49<00:00, 50.52it/s]\n",
            "V Loss: 0.3829, count: 12: 100%|██████████| 625/625 [00:10<00:00, 57.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 12, Train Loss: 0.3845, Val Loss: 0.3829, Train Accuracy: 0.8656, Val Accuracy: 0.8617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "all_downstream_train_loss, all_downstream_val_loss, all_downstream_train_accuracy, all_downstream_val_accuracy = train_downstream_classifier('Adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5pOlJKTriyFH"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "results_dict = {\n",
        "    'elmo_train_loss': all_emlo_train_loss,\n",
        "    'elmo_val_loss': all_elmo_val_loss,\n",
        "    'downstream_train_loss': all_downstream_train_loss,\n",
        "    'downstream_val_loss': all_downstream_val_loss,\n",
        "    'downstream_train_accuracy': all_downstream_train_accuracy,\n",
        "    'downstream_val_accuracy': all_downstream_val_accuracy\n",
        "}\n",
        "\n",
        "with open('results.pkl', 'wb') as pickle_file:\n",
        "  pickle.dump(results_dict, pickle_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create testing dataset\n",
        "\n",
        "test_set = list(test_df['Description'])\n",
        "test_labels = list(test_df['Class Index'])\n",
        "\n",
        "test_dataset = Downstream_Dataset(test_set, test_labels, word_to_ix)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True, num_workers=2, collate_fn=downstream_collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "6Hqmg_EIl_dB"
      },
      "outputs": [],
      "source": [
        "# test using the testing dataset\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "    \n",
        "def test_downstream_classifier():\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=word_to_ix['<pad>'])\n",
        "    downstream_model.load_state_dict(torch.load('best_downstream_model_.pth'))\n",
        "    downstream_model.eval()\n",
        "    \n",
        "    pred_labels = []\n",
        "    true_labels = []\n",
        "    total_loss = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_forward, x_backward, lengths, labels in test_loader:\n",
        "            x_forward = x_forward.cuda()\n",
        "            x_backward = x_backward.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            output = downstream_model(x_forward, x_backward, lengths)\n",
        "\n",
        "            output = output.reshape(-1, output.shape[-1])\n",
        "\n",
        "            loss = loss_fn(output, labels)\n",
        "            total_loss.append(loss.item())\n",
        "\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            pred_labels.extend(predicted.tolist())\n",
        "            true_labels.extend(labels.tolist())\n",
        "\n",
        "    mean_loss = np.mean(total_loss)\n",
        "    \n",
        "    print('Test Loss: {:.4f}'.format(mean_loss))\n",
        "    \n",
        "    # classification report and confusion matrix\n",
        "    print(classification_report(true_labels, pred_labels))\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.4017\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.84      0.87      1900\n",
            "           1       0.92      0.95      0.94      1900\n",
            "           2       0.78      0.85      0.82      1900\n",
            "           3       0.84      0.79      0.81      1900\n",
            "\n",
            "    accuracy                           0.86      7600\n",
            "   macro avg       0.86      0.86      0.86      7600\n",
            "weighted avg       0.86      0.86      0.86      7600\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_downstream_classifier()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "anlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
