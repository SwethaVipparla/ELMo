{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DVe1pr3KFKvQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "df = df.dropna()\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "k1S6Ss7SFKvT",
        "outputId": "9057c88f-1ef3-4bc2-e36d-c493bc2491a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /home2/swethavipparla/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Index</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>[&lt;sos&gt;, reuters, short, sellers, ,, wall, stre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>[&lt;sos&gt;, reuters, private, investment, firm, ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[&lt;sos&gt;, reuters, soaring, crude, prices, plus,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[&lt;sos&gt;, reuters, authorities, have, halted, oi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[&lt;sos&gt;, afp, tearaway, world, oil, prices, ,, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Class Index                                        Description\n",
              "0            3  [<sos>, reuters, short, sellers, ,, wall, stre...\n",
              "1            3  [<sos>, reuters, private, investment, firm, ca...\n",
              "2            3  [<sos>, reuters, soaring, crude, prices, plus,...\n",
              "3            3  [<sos>, reuters, authorities, have, halted, oi...\n",
              "4            3  [<sos>, afp, tearaway, world, oil, prices, ,, ..."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def normalize_unicode(s):\n",
        "    return unicodedata.normalize('NFD', s)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = normalize_unicode(text)\n",
        "    text = re.sub(r\"(.)(\\1{2,})\", r\"\\1\", text)\n",
        "    text = re.sub(r\"[^a-zA-Z.,!?]+\", \" \", text)\n",
        "    text = text.strip().lower()\n",
        "    return text\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "df['Description'] = df['Description'].apply(preprocess_text)\n",
        "df['Description'] = df['Description'].apply(nltk.word_tokenize)\n",
        "df['Description'] = df['Description'].apply(lambda x: ['<sos>'] + x + ['<eos>'])\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CeE4PxpCFKvU"
      },
      "outputs": [],
      "source": [
        "train_set = df['Description']\n",
        "pre_train_set = list(df['Description'][:8000])\n",
        "pre_val_set = list(df['Description'][8000:10000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nKzN3CZCFKvU"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ELMO_Dataset(Dataset):\n",
        "    def __init__(self, data, word_to_ix):\n",
        "        self.data = data\n",
        "        self.word_to_ix = word_to_ix\n",
        "        self.indexed_data = [self.index_sentence(sentence) for sentence in data]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.indexed_data[idx])\n",
        "\n",
        "    def index_sentence(self, sentence):\n",
        "        indexed_sentence = [self.word_to_ix.get(word, self.word_to_ix['<unk>']) for word in sentence]\n",
        "        return indexed_sentence\n",
        "\n",
        "    @staticmethod\n",
        "    def create_vocab(data):\n",
        "        vocab = set()\n",
        "        for sentence in data:\n",
        "            for word in sentence:\n",
        "                vocab.add(word)\n",
        "\n",
        "        vocab.add('<pad>')\n",
        "        vocab.add('<unk>')\n",
        "        vocab.add('<sos>')\n",
        "        vocab.add('<eos>')\n",
        "        return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbuIOGvQFKvU",
        "outputId": "f6aab9f7-3b0d-4460-e570-f516451cfc5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "59352\n"
          ]
        }
      ],
      "source": [
        "word_to_ix = {word: idx for idx, word in enumerate(ELMO_Dataset.create_vocab(train_set))}\n",
        "print(len(word_to_ix))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LElWE0J5FKvV"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "def collate_fn(batch):\n",
        "    batch = sorted(batch, key=lambda x: x.shape[0], reverse=True)\n",
        "    padded_batch = pad_sequence(batch, batch_first=True, padding_value=word_to_ix['<pad>'])\n",
        "    lengths = torch.LongTensor([len(x) for x in batch])\n",
        "\n",
        "    input_tensor = padded_batch[:, :-1]\n",
        "    target_truth = padded_batch[:, 1:]\n",
        "\n",
        "    return input_tensor, target_truth, lengths - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh0lM0plFKvV",
        "outputId": "4c9b64ec-5a7e-48ca-acce-77d429c170ce"
      },
      "outputs": [],
      "source": [
        "pre_train_dataset = ELMO_Dataset(pre_train_set, word_to_ix)\n",
        "\n",
        "pre_val_dataset = ELMO_Dataset(pre_val_set, word_to_ix)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "pre_train_loader = DataLoader(pre_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=4)\n",
        "pre_val_loader = DataLoader(pre_val_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xudp-rpZFKvV",
        "outputId": "1abc7701-dbe7-4117-bdbc-32645eb2fa2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "import gensim.downloader\n",
        "\n",
        "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2rWFfleFKvW",
        "outputId": "5a21ac06-7e04-4322-f467-4391e1d61a3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([59352, 50])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "vocab_size = len(word_to_ix)\n",
        "embedding_dim = glove_vectors.vector_size\n",
        "embedding_matrix = torch.zeros(vocab_size, embedding_dim)\n",
        "\n",
        "special_tokens = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
        "\n",
        "average_vector = np.mean(glove_vectors.vectors, axis=0)\n",
        "\n",
        "for word, i in word_to_ix.items():\n",
        "    if word not in special_tokens:\n",
        "        try:\n",
        "            embedding_matrix[i] = torch.tensor(glove_vectors[word])\n",
        "        except KeyError:\n",
        "            embedding_matrix[i] = torch.tensor(average_vector)\n",
        "\n",
        "    elif word == '<sos>' or word == '<eos>':\n",
        "        embedding_matrix[i] = torch.randn(embedding_dim)\n",
        "    elif word == '<unk>':\n",
        "        embedding_matrix[i] = torch.tensor(average_vector)\n",
        "    else:\n",
        "        embedding_matrix[i] = torch.zeros(embedding_dim)\n",
        "\n",
        "print(embedding_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AF2fDAWlFKvW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "class ELMO(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_dim, num_layers, dropout):\n",
        "        super(ELMO, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        self.lstm = nn.LSTM(embedding_matrix.shape[1], hidden_dim, num_layers, dropout=dropout, batch_first=True, bidirectional=True)\n",
        "        self.linear = nn.Linear(hidden_dim * 2, embedding_matrix.shape[0])\n",
        "\n",
        "    def forward(self, input_tensor, lengths):\n",
        "        embedded = self.embedding(input_tensor)\n",
        "        packed_input = pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=True)\n",
        "        packed_output, _ = self.lstm(packed_input, None)\n",
        "\n",
        "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "        output = self.linear(output)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zliTu400FKvW"
      },
      "outputs": [],
      "source": [
        "model = ELMO(embedding_matrix, 300, 2, 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0RYLZprIFKvX"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sFvUaUuaFKvX"
      },
      "outputs": [],
      "source": [
        "def run_epoch(model, data_loader, loss_fn, epoch, optimizer=None):\n",
        "    if optimizer:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    p_bar = tqdm(data_loader)\n",
        "    for (input_tensor, target_truth, lengths) in p_bar:\n",
        "\n",
        "        input_tensor = input_tensor.cuda()\n",
        "        target_truth = target_truth.cuda()\n",
        "\n",
        "        output = model(input_tensor, lengths)\n",
        "        output = output.reshape(-1, output.shape[2])\n",
        "\n",
        "        loss = loss_fn(output, target_truth.reshape(-1))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if optimizer:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        mean_loss = total_loss / len(data_loader)\n",
        "\n",
        "        p_bar.set_description(f'{\"T\" if optimizer else \"V\"} Loss: {mean_loss:.4f}, count: {epoch}')\n",
        "\n",
        "\n",
        "    return mean_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B_bi722aFKvX",
        "outputId": "81ce2a61-3f61-43c4-c7cf-ac6918968e8e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 8.9388, count: 1: 100%|██████████| 250/250 [00:30<00:00,  8.22it/s]\n",
            "V Loss: 8.5080, count: 1: 100%|██████████| 63/63 [00:02<00:00, 26.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train Loss: 8.9388, Val Loss: 8.5080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 7.8507, count: 2: 100%|██████████| 250/250 [00:27<00:00,  9.05it/s]\n",
            "V Loss: 7.2585, count: 2: 100%|██████████| 63/63 [00:02<00:00, 26.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2, Train Loss: 7.8507, Val Loss: 7.2585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 6.7928, count: 3: 100%|██████████| 250/250 [00:27<00:00,  9.03it/s]\n",
            "V Loss: 6.4858, count: 3: 100%|██████████| 63/63 [00:02<00:00, 26.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 3, Train Loss: 6.7928, Val Loss: 6.4858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 6.0844, count: 4: 100%|██████████| 250/250 [00:28<00:00,  8.76it/s]\n",
            "V Loss: 5.8313, count: 4: 100%|██████████| 63/63 [00:02<00:00, 26.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 4, Train Loss: 6.0844, Val Loss: 5.8313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 5.5757, count: 5: 100%|██████████| 250/250 [00:28<00:00,  8.68it/s]\n",
            "V Loss: 5.5919, count: 5: 100%|██████████| 63/63 [00:02<00:00, 25.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 5, Train Loss: 5.5757, Val Loss: 5.5919\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 5.1049, count: 6: 100%|██████████| 250/250 [00:28<00:00,  8.65it/s]\n",
            "V Loss: 5.1599, count: 6: 100%|██████████| 63/63 [00:02<00:00, 26.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 6, Train Loss: 5.1049, Val Loss: 5.1599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 4.7267, count: 7: 100%|██████████| 250/250 [00:29<00:00,  8.53it/s]\n",
            "V Loss: 4.9137, count: 7: 100%|██████████| 63/63 [00:02<00:00, 25.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 7, Train Loss: 4.7267, Val Loss: 4.9137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 4.3810, count: 8: 100%|██████████| 250/250 [00:28<00:00,  8.73it/s]\n",
            "V Loss: 4.5877, count: 8: 100%|██████████| 63/63 [00:02<00:00, 25.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 8, Train Loss: 4.3810, Val Loss: 4.5877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 4.0975, count: 9: 100%|██████████| 250/250 [00:28<00:00,  8.64it/s]\n",
            "V Loss: 4.3831, count: 9: 100%|██████████| 63/63 [00:02<00:00, 25.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 9, Train Loss: 4.0975, Val Loss: 4.3831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 3.8173, count: 10: 100%|██████████| 250/250 [00:29<00:00,  8.62it/s]\n",
            "V Loss: 4.2147, count: 10: 100%|██████████| 63/63 [00:02<00:00, 25.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10, Train Loss: 3.8173, Val Loss: 4.2147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 3.5577, count: 11: 100%|██████████| 250/250 [00:28<00:00,  8.67it/s]\n",
            "V Loss: 3.9709, count: 11: 100%|██████████| 63/63 [00:02<00:00, 25.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 11, Train Loss: 3.5577, Val Loss: 3.9709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 3.3488, count: 12: 100%|██████████| 250/250 [00:28<00:00,  8.69it/s]\n",
            "V Loss: 3.7398, count: 12: 100%|██████████| 63/63 [00:02<00:00, 25.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 12, Train Loss: 3.3488, Val Loss: 3.7398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 3.1126, count: 13: 100%|██████████| 250/250 [00:28<00:00,  8.75it/s]\n",
            "V Loss: 3.5090, count: 13: 100%|██████████| 63/63 [00:02<00:00, 25.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 13, Train Loss: 3.1126, Val Loss: 3.5090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 2.9170, count: 14: 100%|██████████| 250/250 [00:28<00:00,  8.72it/s]\n",
            "V Loss: 3.3759, count: 14: 100%|██████████| 63/63 [00:02<00:00, 25.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 14, Train Loss: 2.9170, Val Loss: 3.3759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 2.7211, count: 15: 100%|██████████| 250/250 [00:28<00:00,  8.68it/s]\n",
            "V Loss: 3.1422, count: 15: 100%|██████████| 63/63 [00:02<00:00, 25.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 15, Train Loss: 2.7211, Val Loss: 3.1422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 2.5185, count: 16: 100%|██████████| 250/250 [00:28<00:00,  8.67it/s]\n",
            "V Loss: 2.9881, count: 16: 100%|██████████| 63/63 [00:02<00:00, 24.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 16, Train Loss: 2.5185, Val Loss: 2.9881\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 2.2982, count: 17: 100%|██████████| 250/250 [00:28<00:00,  8.72it/s]\n",
            "V Loss: 2.7977, count: 17: 100%|██████████| 63/63 [00:02<00:00, 26.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 17, Train Loss: 2.2982, Val Loss: 2.7977\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 2.0877, count: 18: 100%|██████████| 250/250 [00:28<00:00,  8.72it/s]\n",
            "V Loss: 2.5670, count: 18: 100%|██████████| 63/63 [00:02<00:00, 25.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 18, Train Loss: 2.0877, Val Loss: 2.5670\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 1.9043, count: 19: 100%|██████████| 250/250 [00:28<00:00,  8.70it/s]\n",
            "V Loss: 2.3434, count: 19: 100%|██████████| 63/63 [00:02<00:00, 25.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 19, Train Loss: 1.9043, Val Loss: 2.3434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 1.6847, count: 20: 100%|██████████| 250/250 [00:28<00:00,  8.64it/s]\n",
            "V Loss: 2.1348, count: 20: 100%|██████████| 63/63 [00:02<00:00, 26.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 20, Train Loss: 1.6847, Val Loss: 2.1348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 1.4721, count: 21: 100%|██████████| 250/250 [00:28<00:00,  8.65it/s]\n",
            "V Loss: 1.9507, count: 21: 100%|██████████| 63/63 [00:02<00:00, 25.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 21, Train Loss: 1.4721, Val Loss: 1.9507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 1.2532, count: 22: 100%|██████████| 250/250 [00:29<00:00,  8.61it/s]\n",
            "V Loss: 1.7740, count: 22: 100%|██████████| 63/63 [00:02<00:00, 25.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 22, Train Loss: 1.2532, Val Loss: 1.7740\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 1.0673, count: 23: 100%|██████████| 250/250 [00:28<00:00,  8.70it/s]\n",
            "V Loss: 1.5983, count: 23: 100%|██████████| 63/63 [00:02<00:00, 25.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 23, Train Loss: 1.0673, Val Loss: 1.5983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.8896, count: 24: 100%|██████████| 250/250 [00:28<00:00,  8.77it/s]\n",
            "V Loss: 1.4224, count: 24: 100%|██████████| 63/63 [00:02<00:00, 25.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 24, Train Loss: 0.8896, Val Loss: 1.4224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.7222, count: 25: 100%|██████████| 250/250 [00:28<00:00,  8.67it/s]\n",
            "V Loss: 1.2797, count: 25: 100%|██████████| 63/63 [00:02<00:00, 25.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 25, Train Loss: 0.7222, Val Loss: 1.2797\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.5902, count: 26: 100%|██████████| 250/250 [00:29<00:00,  8.61it/s]\n",
            "V Loss: 1.1607, count: 26: 100%|██████████| 63/63 [00:02<00:00, 24.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 26, Train Loss: 0.5902, Val Loss: 1.1607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.4769, count: 27: 100%|██████████| 250/250 [00:29<00:00,  8.51it/s]\n",
            "V Loss: 1.0473, count: 27: 100%|██████████| 63/63 [00:02<00:00, 26.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 27, Train Loss: 0.4769, Val Loss: 1.0473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.3739, count: 28: 100%|██████████| 250/250 [00:28<00:00,  8.68it/s]\n",
            "V Loss: 0.9593, count: 28: 100%|██████████| 63/63 [00:02<00:00, 25.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 28, Train Loss: 0.3739, Val Loss: 0.9593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.2976, count: 29: 100%|██████████| 250/250 [00:28<00:00,  8.72it/s]\n",
            "V Loss: 0.9101, count: 29: 100%|██████████| 63/63 [00:02<00:00, 25.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 29, Train Loss: 0.2976, Val Loss: 0.9101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.2410, count: 30: 100%|██████████| 250/250 [00:29<00:00,  8.60it/s]\n",
            "V Loss: 0.8522, count: 30: 100%|██████████| 63/63 [00:02<00:00, 26.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 30, Train Loss: 0.2410, Val Loss: 0.8522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.1914, count: 31: 100%|██████████| 250/250 [00:28<00:00,  8.78it/s]\n",
            "V Loss: 0.8046, count: 31: 100%|██████████| 63/63 [00:02<00:00, 25.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 31, Train Loss: 0.1914, Val Loss: 0.8046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.1577, count: 32: 100%|██████████| 250/250 [00:29<00:00,  8.54it/s]\n",
            "V Loss: 0.7811, count: 32: 100%|██████████| 63/63 [00:02<00:00, 24.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 32, Train Loss: 0.1577, Val Loss: 0.7811\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.1294, count: 33: 100%|██████████| 250/250 [00:28<00:00,  8.77it/s]\n",
            "V Loss: 0.7603, count: 33: 100%|██████████| 63/63 [00:02<00:00, 25.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 33, Train Loss: 0.1294, Val Loss: 0.7603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.1102, count: 34: 100%|██████████| 250/250 [00:29<00:00,  8.59it/s]\n",
            "V Loss: 0.7429, count: 34: 100%|██████████| 63/63 [00:02<00:00, 25.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 34, Train Loss: 0.1102, Val Loss: 0.7429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0902, count: 35: 100%|██████████| 250/250 [00:28<00:00,  8.64it/s]\n",
            "V Loss: 0.7427, count: 35: 100%|██████████| 63/63 [00:02<00:00, 24.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 35, Train Loss: 0.0902, Val Loss: 0.7427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0771, count: 36: 100%|██████████| 250/250 [00:28<00:00,  8.77it/s]\n",
            "V Loss: 0.7226, count: 36: 100%|██████████| 63/63 [00:02<00:00, 26.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 36, Train Loss: 0.0771, Val Loss: 0.7226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0655, count: 37: 100%|██████████| 250/250 [00:28<00:00,  8.64it/s]\n",
            "V Loss: 0.6913, count: 37: 100%|██████████| 63/63 [00:02<00:00, 25.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 37, Train Loss: 0.0655, Val Loss: 0.6913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0557, count: 38: 100%|██████████| 250/250 [00:28<00:00,  8.68it/s]\n",
            "V Loss: 0.6867, count: 38: 100%|██████████| 63/63 [00:02<00:00, 25.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 38, Train Loss: 0.0557, Val Loss: 0.6867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0474, count: 39: 100%|██████████| 250/250 [00:28<00:00,  8.66it/s]\n",
            "V Loss: 0.6883, count: 39: 100%|██████████| 63/63 [00:02<00:00, 25.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 39, Train Loss: 0.0474, Val Loss: 0.6883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0406, count: 40: 100%|██████████| 250/250 [00:28<00:00,  8.70it/s]\n",
            "V Loss: 0.6773, count: 40: 100%|██████████| 63/63 [00:02<00:00, 24.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 40, Train Loss: 0.0406, Val Loss: 0.6773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0354, count: 41: 100%|██████████| 250/250 [00:28<00:00,  8.64it/s]\n",
            "V Loss: 0.6744, count: 41: 100%|██████████| 63/63 [00:02<00:00, 24.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 41, Train Loss: 0.0354, Val Loss: 0.6744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0309, count: 42: 100%|██████████| 250/250 [00:29<00:00,  8.55it/s]\n",
            "V Loss: 0.6716, count: 42: 100%|██████████| 63/63 [00:02<00:00, 25.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 42, Train Loss: 0.0309, Val Loss: 0.6716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0268, count: 43: 100%|██████████| 250/250 [00:29<00:00,  8.59it/s]\n",
            "V Loss: 0.6792, count: 43: 100%|██████████| 63/63 [00:02<00:00, 24.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 43, Train Loss: 0.0268, Val Loss: 0.6792\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0229, count: 44: 100%|██████████| 250/250 [00:28<00:00,  8.74it/s]\n",
            "V Loss: 0.6598, count: 44: 100%|██████████| 63/63 [00:02<00:00, 26.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 44, Train Loss: 0.0229, Val Loss: 0.6598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0202, count: 45: 100%|██████████| 250/250 [00:28<00:00,  8.65it/s]\n",
            "V Loss: 0.6627, count: 45: 100%|██████████| 63/63 [00:02<00:00, 25.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 45, Train Loss: 0.0202, Val Loss: 0.6627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0176, count: 46: 100%|██████████| 250/250 [00:28<00:00,  8.62it/s]\n",
            "V Loss: 0.6487, count: 46: 100%|██████████| 63/63 [00:02<00:00, 24.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 46, Train Loss: 0.0176, Val Loss: 0.6487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0174, count: 47: 100%|██████████| 250/250 [00:28<00:00,  8.71it/s]\n",
            "V Loss: 0.6676, count: 47: 100%|██████████| 63/63 [00:02<00:00, 23.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 47, Train Loss: 0.0174, Val Loss: 0.6676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0163, count: 48: 100%|██████████| 250/250 [00:28<00:00,  8.68it/s]\n",
            "V Loss: 0.6530, count: 48: 100%|██████████| 63/63 [00:02<00:00, 26.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 48, Train Loss: 0.0163, Val Loss: 0.6530\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0126, count: 49: 100%|██████████| 250/250 [00:29<00:00,  8.60it/s]\n",
            "V Loss: 0.6441, count: 49: 100%|██████████| 63/63 [00:02<00:00, 25.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 49, Train Loss: 0.0126, Val Loss: 0.6441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "T Loss: 0.0108, count: 50: 100%|██████████| 250/250 [00:29<00:00,  8.59it/s]\n",
            "V Loss: 0.6475, count: 50: 100%|██████████| 63/63 [00:02<00:00, 25.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 50, Train Loss: 0.0108, Val Loss: 0.6475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 50\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "all_val_loss = []\n",
        "all_train_loss = []\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = run_epoch(model, pre_train_loader, loss_fn, epoch+1, optimizer)\n",
        "    all_train_loss.append(train_loss)\n",
        "    with torch.no_grad():\n",
        "        val_loss = run_epoch(model, pre_val_loader, loss_fn, epoch+1)\n",
        "        all_val_loss.append(val_loss)\n",
        "\n",
        "    print('Epoch: {}, Train Loss: {:.4f}, Val Loss: {:.4f}'.format(epoch+1, train_loss, val_loss))\n",
        "    if val_loss < best_val_loss:\n",
        "        counter = 0\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_lstm_model.pth')\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter == 3:\n",
        "            break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
